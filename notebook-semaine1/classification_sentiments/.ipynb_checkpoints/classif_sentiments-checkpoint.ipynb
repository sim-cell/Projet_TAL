{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82972f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584c4800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alway', 'anoth', 'anyon', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'describ', 'don', 'du', 'eith', 'elsewher', 'everyon', 'everywher', 'fir', 'fiv', 'form', 'furth', 'giv', 'hav', 'henc', 'hereaft', 'howev', 'latt', 'mad', 'meanwhil', 'min', 'mor', 'moreov', 'mov', 'nam', 'neith', 'nev', 'nin', 'non', 'noon', 'nowher', 'otherwis', 'ourselv', 'perhap', 'pleas', 'rath', 'sam', 'se', 'sid', 'sinc', 'sincer', 'som', 'someon', 'sometim', 'somewher', 'tak', 'themselv', 'thenc', 'ther', 'thereaft', 'therefor', 'thes', 'thos', 'thre', 'togeth', 'twelv', 'vi', 'wel', 'wer', 'whatev', 'whenc', 'whenev', 'wher', 'whereaft', 'wherev', 'wheth', 'whil', 'whith', 'whoev', 'whol', 'whos', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m vect_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrip_accents\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_words\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      4\u001b[0m model_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCountVectorizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mvect_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvect_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLinearSVC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\M1\\RITAL\\Projet_TAL\\notebook-semaine1\\classification_sentiments\\evaluation.py:55\u001b[0m, in \u001b[0;36mprediction_generator\u001b[1;34m(preprocessor, vectorizer, vect_params, model, model_params, save)\u001b[0m\n\u001b[0;32m     53\u001b[0m vec \u001b[38;5;241m=\u001b[39m vectorizer(preprocessor\u001b[38;5;241m=\u001b[39mpreprocessor,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvect_params)\n\u001b[0;32m     54\u001b[0m txts_train \u001b[38;5;241m=\u001b[39m vec\u001b[38;5;241m.\u001b[39mfit_transform(alltxts_train)\n\u001b[1;32m---> 55\u001b[0m txts_test \u001b[38;5;241m=\u001b[39m \u001b[43mvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43malltxts_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# [X_train, X_test, y_train, y_test]  = train_test_split(txts_train, labs_train, test_size=0.2, random_state=10, shuffle=True)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# ModÃ©lisation \u001b[39;00m\n\u001b[0;32m     60\u001b[0m mod \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1434\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_vocabulary()\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[1;32m-> 1434\u001b[0m _, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1436\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1275\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1278\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:110\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(text)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m text: \u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchiffre_suppression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mponc_suppression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m vect_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrip_accents\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_words\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      4\u001b[0m model_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m}\n",
      "File \u001b[1;32m~\\Desktop\\M1\\RITAL\\Projet_TAL\\notebook-semaine1\\classification_sentiments\\utils_donnee.py:69\u001b[0m, in \u001b[0;36mstem\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     67\u001b[0m french_stemmer \u001b[38;5;241m=\u001b[39m FrenchStemmer()\n\u001b[0;32m     68\u001b[0m words \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrench\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m stemmed_words \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mfrench_stemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     70\u001b[0m stemmed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemmed_words)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stemmed_text\n",
      "File \u001b[1;32m~\\Desktop\\M1\\RITAL\\Projet_TAL\\notebook-semaine1\\classification_sentiments\\utils_donnee.py:69\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     67\u001b[0m french_stemmer \u001b[38;5;241m=\u001b[39m FrenchStemmer()\n\u001b[0;32m     68\u001b[0m words \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrench\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m stemmed_words \u001b[38;5;241m=\u001b[39m [\u001b[43mfrench_stemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m     70\u001b[0m stemmed_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemmed_words)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stemmed_text\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\nltk\\stem\\snowball.py:2577\u001b[0m, in \u001b[0;36mFrenchStemmer.stem\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(word)):\n\u001b[0;32m   2576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word[\u001b[38;5;241m-\u001b[39mi] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__vowels:\n\u001b[1;32m-> 2577\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2579\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m word[\u001b[38;5;241m-\u001b[39mi] \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\xE9\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\xE8\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocessor = lambda text: stem(remove_tags(chiffre_suppression(ponc_suppression(text))))\n",
    "vect_params = {'lowercase':True,'strip_accents':'ascii','stop_words':'english'}\n",
    "\n",
    "model_params = {'random_state':0}\n",
    "predictions = prediction_generator(preprocessor=preprocessor,\n",
    "                                   vectorizer=CountVectorizer,\n",
    "                                   vect_params=vect_params,\n",
    "                                   model=LinearSVC,\n",
    "                                   model_params=model_params,\n",
    "                                   save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829e5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alway', 'anoth', 'anyon', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'describ', 'don', 'du', 'eith', 'elsewher', 'everyon', 'everywher', 'fir', 'fiv', 'form', 'furth', 'giv', 'hav', 'henc', 'hereaft', 'howev', 'latt', 'mad', 'meanwhil', 'min', 'mor', 'moreov', 'mov', 'nam', 'neith', 'nev', 'nin', 'non', 'noon', 'nowher', 'otherwis', 'ourselv', 'perhap', 'pleas', 'rath', 'sam', 'se', 'sid', 'sinc', 'sincer', 'som', 'someon', 'sometim', 'somewher', 'tak', 'themselv', 'thenc', 'ther', 'thereaft', 'therefor', 'thes', 'thos', 'thre', 'togeth', 'twelv', 'vi', 'wel', 'wer', 'whatev', 'whenc', 'whenev', 'wher', 'whereaft', 'wherev', 'wheth', 'whil', 'whith', 'whoev', 'whol', 'whos', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC\\miniconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\\n\"\n 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!\\n'\n \"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman Philip Stevens (James Stewart) who is flying them & a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) & her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) & his two accomplice's Banker (Monte Markham) & Wilson (Michael Pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in & having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...<br /><br />Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson & while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking & then the crashing (didn't he see the oil rig?) & sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) & submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces & a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships & helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background.<br /><br />The home video & theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes & the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions & interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow & not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.<br /><br />The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old & frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do & there are plenty of other familiar faces to look out for too.<br /><br />Airport '77 is the most disaster orientated of the three Airport films so far & I liked the ideas behind it even if they were a bit silly, the production & bland direction doesn't help though & a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979).\\n\"\n ...\n \"Brendan Filone is the absolute best character in The Sopranos. he died by getting shot in the eye. This was the best and well orchestrated scene ever in the Sopranos. Brendan Filone is too good. Brendan Filone shall haunt Uncle Junior in his dreams until Uncle Junior can't take it anymore. Brendan Filone is the best character. Brendan Filone was killed in episode # 3, Denial, anger, acceptance. But his legacy will live on forever. Brendan Filone is the best character on Sopranos! Brendan Filone is the best character ever. I recommend this show to anyone who likes Drama and wants to see good death scenes and great directing and producing, because it doesn't get any better than this series. Brendan Filone is the best.\\n\"\n 'Chase has created a true phenomenon with The Sopranos. Unfaltering performances, rock-solid writing, and some great music make up what has become quite possibly the best show ever.<br /><br />All of the cast are strong, but Falco and Gandolfini earned every inch of those Emmy\\'s. Anyone who doubts this need only sample a few episodes; particularly from the first few seasons. James Gandolfini is absolutely fierce, absolutely terrifying, and you still find yourself loving him - mesmerized by him.<br /><br />Many people that I\\'ve spoken to about The Sopranos (who haven\\'t seen it yet) will say \"I\\'m just not a fan of mafia movies/shows\". Whatever. Run - don\\'t walk - and get it. Those same people usually love \"E.R.\", but I bet they don\\'t much care for hospitals... It\\'s not about the context.\\n'\n 'Having only seen two of his pictures previously, I\\'ve come to terms with Altman. Before, though, I always labeled his style of film-making \"boring.\" You just have to be in the right mind to appreciate his crazy genius.<br /><br />\"HealtH\" is fairly underrated, and very questionably out of print. In fact, I don\\'t think it\\'s ever even been issued to VHS. Why is that? When all of these crappy films get DVD releases daily, this one is left behind for no good reason? Hones'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m vect_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrip_accents\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_words\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     73\u001b[0m model_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m---> 74\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCountVectorizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mvect_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvect_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLinearSVC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m, in \u001b[0;36mprediction_generator\u001b[1;34m(preprocessor, vectorizer, vect_params, model, model_params, save)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# PrÃ©diction\u001b[39;00m\n\u001b[0;32m     60\u001b[0m pred_train \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[1;32m---> 61\u001b[0m pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43malltxts_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(pred_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m save_pred(pred_test)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:332\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    329\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:989\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    984\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m             )\n\u001b[1;32m--> 989\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    995\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\\n\"\n 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!\\n'\n \"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman Philip Stevens (James Stewart) who is flying them & a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) & her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) & his two accomplice's Banker (Monte Markham) & Wilson (Michael Pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in & having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...<br /><br />Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson & while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking & then the crashing (didn't he see the oil rig?) & sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) & submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces & a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships & helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background.<br /><br />The home video & theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes & the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions & interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow & not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.<br /><br />The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old & frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do & there are plenty of other familiar faces to look out for too.<br /><br />Airport '77 is the most disaster orientated of the three Airport films so far & I liked the ideas behind it even if they were a bit silly, the production & bland direction doesn't help though & a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979).\\n\"\n ...\n \"Brendan Filone is the absolute best character in The Sopranos. he died by getting shot in the eye. This was the best and well orchestrated scene ever in the Sopranos. Brendan Filone is too good. Brendan Filone shall haunt Uncle Junior in his dreams until Uncle Junior can't take it anymore. Brendan Filone is the best character. Brendan Filone was killed in episode # 3, Denial, anger, acceptance. But his legacy will live on forever. Brendan Filone is the best character on Sopranos! Brendan Filone is the best character ever. I recommend this show to anyone who likes Drama and wants to see good death scenes and great directing and producing, because it doesn't get any better than this series. Brendan Filone is the best.\\n\"\n 'Chase has created a true phenomenon with The Sopranos. Unfaltering performances, rock-solid writing, and some great music make up what has become quite possibly the best show ever.<br /><br />All of the cast are strong, but Falco and Gandolfini earned every inch of those Emmy\\'s. Anyone who doubts this need only sample a few episodes; particularly from the first few seasons. James Gandolfini is absolutely fierce, absolutely terrifying, and you still find yourself loving him - mesmerized by him.<br /><br />Many people that I\\'ve spoken to about The Sopranos (who haven\\'t seen it yet) will say \"I\\'m just not a fan of mafia movies/shows\". Whatever. Run - don\\'t walk - and get it. Those same people usually love \"E.R.\", but I bet they don\\'t much care for hospitals... It\\'s not about the context.\\n'\n 'Having only seen two of his pictures previously, I\\'ve come to terms with Altman. Before, though, I always labeled his style of film-making \"boring.\" You just have to be in the right mind to appreciate his crazy genius.<br /><br />\"HealtH\" is fairly underrated, and very questionably out of print. In fact, I don\\'t think it\\'s ever even been issued to VHS. Why is that? When all of these crappy films get DVD releases daily, this one is left behind for no good reason? Hones'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from collections import Counter\n",
    "from utils_donnee import *\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def save_pred(pred):\n",
    "    \"\"\" Sauvegarder les prÃ©dictions dans un fichier\n",
    "    EntrÃ©e : Array (de M et C)\n",
    "    Sortie : None + file dans predictions\n",
    "    \"\"\"\n",
    "    directory = \"./predictions\"\n",
    "    index = len(os.listdir(directory))+1 #nb de fichiers + 1 = l'indice du nouveau fichier\n",
    "    filename = os.path.join(directory,f'test_{index}.txt')\n",
    "    np.savetxt(filename, pred, fmt=\"%s\")\n",
    "\n",
    "\n",
    "def prediction_generator(preprocessor,vectorizer,vect_params,model,model_params,save=True):\n",
    "    \"\"\"Faire une prediction sur le fichier selon preprocessor, vectorizer, model donnÃ©s.\n",
    "    EntrÃ©e : file : nom du fichier\n",
    "             preprocessor : preprocessor pour nettoyer les donnÃ©es\n",
    "             vectorizer : vectorizer Ã  utiliser\n",
    "             vect_params : parametres de vectorizer Ã  utiliser\n",
    "             model : modÃ¨le Ã  utiliser\n",
    "             model_params : paramÃ¨tres du modÃ¨le Ã  utiliser\n",
    "             save : si True, sauvegarder le rÃ©sultat dans un fichier\n",
    "    Sortie : Array de M et C + fichier contenant ce vecteur \n",
    "    \"\"\"\n",
    "\n",
    "    # chargement des donnÃ©es train \n",
    "    alltxts_train,labs_train = load_movies(\"./datasets/movies/movies1000/\")\n",
    "    # chargement des donnÃ©es test\n",
    "    alltxts_test = load_movies_test(\"./datasets/movies/testSentiment.txt\")\n",
    "\n",
    "    # Vectorization\n",
    "    vec = vectorizer(preprocessor=preprocessor,**vect_params)\n",
    "    txts_train = vec.fit_transform(alltxts_train)\n",
    "\n",
    "    # Training\n",
    "    [X_train, X_test, y_train, y_test]  = train_test_split(txts_train, labs_train, test_size=0.2, random_state=10, shuffle=True)\n",
    "\n",
    "    # ModÃ©lisation \n",
    "    mod = model(**model_params)\n",
    "    mod.fit(txts_train,labs_train)\n",
    "\n",
    "    # PrÃ©diction\n",
    "    pred_train = mod.predict(X_train)\n",
    "    pred_test = mod.predict(alltxts_test)\n",
    "\n",
    "    pred = np.where(pred_test == 0, \"N\", \"P\")\n",
    "    save_pred(pred_test)\n",
    "    if save==True:\n",
    "        save_pred(pred_test)\n",
    "\n",
    "    return pred\n",
    "\n",
    "preprocessor = lambda text: stem(remove_tags(chiffre_suppression(ponc_suppression(text))))\n",
    "vect_params = {'lowercase':True,'strip_accents':'ascii','stop_words':'english'}\n",
    "\n",
    "model_params = {'random_state':0}\n",
    "predictions = prediction_generator(preprocessor=preprocessor,\n",
    "                                   vectorizer=CountVectorizer,\n",
    "                                   vect_params=vect_params,\n",
    "                                   model=LinearSVC,\n",
    "                                   model_params=model_params,\n",
    "                                   save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9350d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
